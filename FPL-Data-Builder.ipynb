{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b91a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrish\\AppData\\Local\\Temp/ipykernel_19808/89644023.py:27: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[col] = df[col].str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "from numpy.lib.index_tricks import _diag_indices_from\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from os.path import dirname, join\n",
    "import os\n",
    "\n",
    "def import_merged_gw(season):\n",
    "    \"\"\" Function to call merged_gw.csv file in every data/season folder\n",
    "    Args:\n",
    "        season (str): Name of the folder season that contains the merged_gw.csv file\n",
    "    \"\"\"\n",
    "\n",
    "    path = os.getcwd()\n",
    "    filename = 'merged_gw.csv'\n",
    "    season_path = join(dirname(dirname(\"__file__\")), path, 'data', season, 'gws', filename)\n",
    "    return season_path\n",
    "\n",
    "def clean_players_name_string(df, col='name'):\n",
    "    \"\"\" Clean the imported file 'name' column because it has different patterns between seasons\n",
    "    Args:\n",
    "        df: merged df for all the seasons that have been imported\n",
    "        col: name of the column for cleanup\n",
    "    \"\"\"\n",
    "    #replace _ with space in name column\n",
    "    df[col] = df[col].str.replace('_', ' ')\n",
    "    #remove number in name column\n",
    "    df[col] = df[col].str.replace('\\d+', '')\n",
    "    #trim name column\n",
    "    df[col] = df[col].str.strip()\n",
    "    return df\n",
    "\n",
    "def filter_players_exist_latest(df, col='position'):\n",
    "    \"\"\" Fill in null 'position' (data that only available in 20-21 season) into previous seasons. \n",
    "        Null meaning that player doesnt exist in latest season hence can exclude.\n",
    "    \"\"\"\n",
    "\n",
    "    df[col] = df.groupby('name')[col].apply(lambda x: x.ffill().bfill())\n",
    "    df = df[df[col].notnull()]\n",
    "    return df\n",
    "\n",
    "def get_opponent_team_name(df):\n",
    "    \"\"\" Find team name from master_team_list file and match with the merged df \n",
    "    \"\"\"\n",
    "\n",
    "    path = os.getcwd()\n",
    "    filename = 'master_team_list.csv'\n",
    "    team_path = join(dirname(dirname(\"__file__\")), path, 'data', filename)\n",
    "    df_team = pd.read_csv(team_path)\n",
    "\n",
    "    #create id column for both df_team and df\n",
    "    df['id'] = df['season'].astype(str) + '_' + df['opponent_team'].astype(str)\n",
    "    df_team['id'] = df_team['season'].astype(str) + '_' + df_team['team'].astype(str)\n",
    "\n",
    "    #merge two dfs\n",
    "    df = pd.merge(df, df_team, on = 'id', how = 'left')\n",
    "\n",
    "    #rename column\n",
    "    df = df.rename(columns={\"team_name\": \"opp_team_name\"})\n",
    "    return df\n",
    "\n",
    "def export_cleaned_data(df):\n",
    "    \"\"\" Function to export merged df into specified folder\n",
    "    Args:\n",
    "        path (str): Path of the folder\n",
    "        filename(str): Name of the file\n",
    "    \"\"\"\n",
    "\n",
    "    path = os.getcwd()\n",
    "    filename = 'cleaned_merged_seasons.csv'\n",
    "    filepath = join(dirname(dirname(\"__file__\")), path, 'data', filename)\n",
    "    df.to_csv(filepath, encoding = 'utf-8')\n",
    "    return df\n",
    "def merge_data():\n",
    "    \"\"\" Merge all the data and export to a new file\n",
    "    \"\"\"\n",
    "    season_latin = [ '2020-21', '2021-22'] \n",
    "    encoding_latin = [ 'utf-8', 'utf-8']\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for i,j in zip(season_latin, encoding_latin):\n",
    "        data = pd.read_csv(import_merged_gw(season=f'{i}'), encoding=f'{j}')\n",
    "        data['season'] = i\n",
    "        df = df.append(data, ignore_index=True, sort=False)\n",
    "\n",
    "    df = df[['season','name', 'position', 'team', 'assists','bonus','bps','clean_sheets','creativity','element','fixture','goals_conceded','goals_scored','ict_index','influence','kickoff_time','minutes','opponent_team','own_goals','penalties_missed','penalties_saved','red_cards','round','saves','selected','team_a_score','team_h_score','threat','total_points','transfers_balance','transfers_in','transfers_out','value','was_home','yellow_cards','GW']]\n",
    "\n",
    "    df = clean_players_name_string(df, col='name')\n",
    "    df = filter_players_exist_latest(df, col='position')\n",
    "    df = get_opponent_team_name(df)\n",
    "\n",
    "    df = df[['season_x', 'name', 'position', 'team_x', 'assists', 'bonus', 'bps',\n",
    "       'clean_sheets', 'creativity', 'element', 'fixture', 'goals_conceded',\n",
    "       'goals_scored', 'ict_index', 'influence', 'kickoff_time', 'minutes',\n",
    "       'opponent_team', 'opp_team_name', 'own_goals', 'penalties_missed', 'penalties_saved',\n",
    "       'red_cards', 'round', 'saves', 'selected', 'team_a_score',\n",
    "       'team_h_score', 'threat', 'total_points', 'transfers_balance',\n",
    "       'transfers_in', 'transfers_out', 'value', 'was_home', 'yellow_cards',\n",
    "       'GW']]\n",
    "    \n",
    "    export_cleaned_data(df)\n",
    "\n",
    "def main():\n",
    "    merge_data()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65d7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
