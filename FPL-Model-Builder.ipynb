{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CNEmUecdMg6J"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout=open('test_results.txt','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RdUNK5Y8My8X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season_x', 'name', 'position', 'team_x', 'opp_team_name'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/mergedDataset.csv',index_col=0)\n",
    "data.drop(['kickoff_time'],axis=1,inplace=True)\n",
    "obj_cols=data.columns[data.dtypes==object]\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hfz9yy3KiHLw"
   },
   "outputs": [],
   "source": [
    "data_refined = data.loc[:,[i for i in list(data.columns) if i not in ['name','team_x', 'opp_team_name', 'season_x']]]\n",
    "data_refined = pd.get_dummies(data_refined, columns = ['position', 'GW'], drop_first=True)\n",
    "\n",
    "cols=data_refined.columns[data_refined.isna().sum()>0]\n",
    "for c in cols:\n",
    "    data_refined[c].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iqOsfIdigFL",
    "outputId": "71a51f84-a22c-4778-f4d8-d13b6897acc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_refined.columns[data_refined.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mBVRkJMBM0oT"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_refined.loc[:, data_refined.columns != 'total_points'], data_refined['total_points'], test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c6o9oDHiM2Y_"
   },
   "outputs": [],
   "source": [
    "results_train = {}\n",
    "results_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Abs9BKXkM4ZB",
    "outputId": "cad1207a-47ca-4e8f-eb3d-a96e6deb8f8a"
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "reg = RandomForestRegressor(random_state=0, criterion = 'mse')\n",
    "#Apply grid search for best parameters\n",
    "params = {'randomforestregressor__n_estimators' : range(100,500,200),\n",
    "          'randomforestregressor__min_samples_split' : range(2,10,3)}\n",
    "pipe = make_pipeline(reg)\n",
    "grid = GridSearchCV(pipe, param_grid = params, scoring='neg_mean_squared_error', n_jobs=-1, cv=5)\n",
    "reg = grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*30+\"Random Forest\"+\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_7Bcf4-M-ff",
    "outputId": "de8567de-88f6-40fc-d82a-d892a24d0ddc"
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Best MSE for Random Forest Regressor: ', grid.best_score_)\n",
    "print(f'Best Parameters for Random Forest Regressor: Estimators: {grid.best_estimator_} and Min Samples Split: {grid.n_splits_} Params: {grid.best_params_}')\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "tr_err = mean_squared_error(y_train_pred, y_train)\n",
    "ts_err = mean_squared_error(y_test_pred, y_test)\n",
    "print(\"Training Error: \" + str(tr_err)+ \" Testing Error: \" + str(ts_err))\n",
    "results_train['random_forest'] = tr_err\n",
    "results_test['random_forest'] = ts_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*30+\"Ridge Linear Regression\"+\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5lnolOs3QI-6"
   },
   "outputs": [],
   "source": [
    "#Ridge Linear Regression\n",
    "reg = Ridge()\n",
    "#Apply grid search for best parameters\n",
    "params = {'ridge__alpha':[0.0001, 0.01, 0.1, 0.5, 0.9],\n",
    "          'ridge__solver':['lsqr']}\n",
    "pipe = make_pipeline(reg)\n",
    "grid = GridSearchCV(pipe, param_grid = params, scoring='neg_mean_squared_error', n_jobs=-1, cv=5)\n",
    "reg = grid.fit(X_train, y_train)\n",
    "print('Best MSE: ', grid.best_score_)\n",
    "print('Best Parameters: ', grid.best_estimator_)\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "tr_err = mean_squared_error(y_train_pred, y_train)\n",
    "ts_err = mean_squared_error(y_test_pred, y_test)\n",
    "print(\"Training Error: \" + str(tr_err)+ \" Testing Error: \" + str(ts_err))\n",
    "results_train['Ridge_regression'] = tr_err\n",
    "results_test['Ridge_regression'] = ts_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*30+\"LinearRegression\"+\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rvvpvHgYQMbt"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Linear Regression\n",
    "reg = LinearRegression()\n",
    "#Apply grid search for best parameters\n",
    "params = {}\n",
    "pipe = make_pipeline(reg)\n",
    "grid = GridSearchCV(pipe, param_grid = params, scoring='neg_mean_squared_error', n_jobs=-1,  cv=5)\n",
    "reg = grid.fit(X_train, y_train)\n",
    "print('Best MSE: ', grid.best_score_)\n",
    "print('Best Parameters: ', grid.best_estimator_)\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "tr_err = mean_squared_error(y_train_pred, y_train)\n",
    "ts_err = mean_squared_error(y_test_pred, y_test)\n",
    "print(\"Training Error: \" + str(tr_err)+ \" Testing Error: \" + str(ts_err))\n",
    "results_train['Linear_regression'] = tr_err\n",
    "results_test['Linear_regression'] = ts_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*30+\"Gradient Boosting\"+\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2UAGFmuYQPvv"
   },
   "outputs": [],
   "source": [
    "#GBR\n",
    "reg = GradientBoostingRegressor()\n",
    "params = {'gradientboostingregressor__n_estimators' : range(100,300,50),\n",
    "          'gradientboostingregressor__min_samples_split' : range(2,10,2)}\n",
    "pipe = make_pipeline(reg)\n",
    "grid = GridSearchCV(pipe, param_grid = params, scoring='neg_mean_squared_error', n_jobs=-1,cv=5)\n",
    "reg = grid.fit(X_train, y_train)\n",
    "print('Best MSE: ', grid.best_score_)\n",
    "print('Best Parameters: ', grid.best_estimator_)\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "tr_err = mean_squared_error(y_train_pred, y_train)\n",
    "ts_err = mean_squared_error(y_test_pred, y_test)\n",
    "print(\"Training Error: \" + str(tr_err)+ \" Testing Error: \" + str(ts_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*30+\"LASSO Linear\"+\"*\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1wYDyD9iQSG_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hrish\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5271.737981096274, tolerance: 20.905738539475514\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Lasso Linear Regression\n",
    "reg = linear_model.Lasso()\n",
    "#Apply grid search for best parameters\n",
    "params = {'lasso__alpha':[0.001, 0.01, 0.1, 0.5, 0.9]}\n",
    "pipe = make_pipeline(reg)\n",
    "grid = GridSearchCV(pipe, param_grid = params, scoring='neg_mean_squared_error', n_jobs=-1, cv=5)\n",
    "reg = grid.fit(X_train, y_train)\n",
    "print('Best MSE: ', grid.best_score_)\n",
    "print('Best Parameters: ', grid.best_estimator_)\n",
    "\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "tr_err = mean_squared_error(y_train_pred, y_train)\n",
    "ts_err = mean_squared_error(y_test_pred, y_test)\n",
    "print(\"Training Error: \" + str(tr_err)+ \" Testing Error: \" + str(ts_err))\n",
    "results_train['Lasso_regression'] = tr_err\n",
    "results_test['Lasso_regression'] = ts_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MU3f36UAX3d9"
   },
   "outputs": [],
   "source": [
    "sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
